{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UZFXjWiCRw5i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "fe4K5gISR4gI",
    "outputId": "32ba556c-af42-4574-9bd2-7d6ca73715bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "0         4     10      4     8      4      6      7      9      6      7   \n",
       "1         5      5      6     8      3      5      7     10      9      7   \n",
       "2         5      5      5     7      2      1     15      5      3     12   \n",
       "3         3      1      4     1      1      7      8      6      8      7   \n",
       "4         2      3      2     2      1      5      4      5      6      2   \n",
       "...     ...    ...    ...   ...    ...    ...    ...    ...    ...    ...   \n",
       "3495      4      7      5     5      5      7      7      5      8      6   \n",
       "3496      4      9      5     7      3      6     11      2      8      8   \n",
       "3497      4      5      5     8      2      9     15      1      6      5   \n",
       "3498      3      9      5     7      5     12      5      1      6      8   \n",
       "3499      2      8      2     6      1     12      3      9      4     13   \n",
       "\n",
       "      x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx letter  \n",
       "0         6      7      2      8      9     10      B  \n",
       "1         6      5      3      8      4      8      D  \n",
       "2         9      4      0      8      3      6      F  \n",
       "3        10      8      3     10      1      8      U  \n",
       "4         2      5      1      7      1      6      L  \n",
       "...     ...    ...    ...    ...    ...    ...    ...  \n",
       "3495      5      9      3      8      6      9      E  \n",
       "3496     12      8      1     11      1      7      T  \n",
       "3497     11      9      0      8      0      8      T  \n",
       "3498      4      5      1      8      5     10      I  \n",
       "3499      4     12      1      6      0      8      J  \n",
       "\n",
       "[3500 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('val.csv')\n",
    "val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8h9LvDhjSEdK"
   },
   "outputs": [],
   "source": [
    "#we will one hot encode the labels\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "def encode_label(col):\n",
    "  enc = LabelEncoder()\n",
    "  enc.fit(col)\n",
    "  enc_col = enc.transform(col)\n",
    "\n",
    "  ohe = OneHotEncoder()\n",
    "  encoded = ohe.fit(enc_col.reshape(-1,1))\n",
    "  \n",
    "  return encoded.transform(enc_col.reshape(-1,1)).toarray()\n",
    "\n",
    "labels = train.pop('letter')\n",
    "val_labels = val.pop('letter')\n",
    "labels = encode_label(labels)\n",
    "val_labels = encode_label(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mde8gqKESIU7"
   },
   "outputs": [],
   "source": [
    "train = train.values.astype('float32')\n",
    "val = val.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewlsIXUhSJuc",
    "outputId": "95aa80e3-1a77-4b61-859f-050b3da0dce8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6596851 , -0.31614068, -0.31614068, ..., -0.6596851 ,\n",
       "        -1.0032295 , -1.346774  ],\n",
       "       [ 1.4015814 , -0.31614068, -0.31614068, ..., -0.31614068,\n",
       "         1.058037  ,  0.7144926 ],\n",
       "       [-0.6596851 ,  0.02740375, -0.31614068, ..., -0.31614068,\n",
       "        -0.31614068, -1.346774  ],\n",
       "       ...,\n",
       "       [ 0.7144926 ,  0.7144926 ,  0.7144926 , ...,  0.7144926 ,\n",
       "         0.7144926 ,  0.02740375],\n",
       "       [ 1.058037  , -0.6596851 , -1.0032295 , ..., -2.0338628 ,\n",
       "        -0.31614068, -2.0338628 ],\n",
       "       [ 1.4015814 ,  0.7144926 ,  0.02740375, ...,  0.7144926 ,\n",
       "         1.4015814 ,  0.7144926 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(train.shape[1]):\n",
    "#   m = np.mean(train[:, i])\n",
    "#   s = np.std(train[:, i])\n",
    "#   for j in range(train.shape[0]):\n",
    "#     train[j, i] = (train[j, i]-m)/s\n",
    "\n",
    "mean_x = train.mean().astype(np.float32)\n",
    "std = train.std().astype(np.float32)\n",
    "train = (train-mean_x)/std\n",
    "\n",
    "val_mean = val.mean().astype(np.float32)\n",
    "val_std = val.std().astype(np.float32)\n",
    "val = (val-val_mean)/val_std\n",
    "\n",
    "train = train.T\n",
    "labels = labels.T\n",
    "val = val.T\n",
    "val_labels = val_labels.T\n",
    "\n",
    "val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "J6drYGVMSLkj"
   },
   "outputs": [],
   "source": [
    "#for a particular layer\n",
    "#n_x = number of inputs\n",
    "#n_h = number of units\n",
    "#n_y = number of outputs\n",
    " \n",
    "#this function just initializes the parameters\n",
    "def initialize_parameters(layers_dims):\n",
    "  \n",
    "  \n",
    "  parameters = {}\n",
    "  L = len(layers_dims) \n",
    " \n",
    "  for l in range(1, L):\n",
    "    parameters[\"W\" + str(l)] = nr.randn(layers_dims[l], layers_dims[l-1]) * 0.0001\n",
    "    parameters[\"b\" + str(l)] = np.zeros((layers_dims[l], 1))\n",
    " \n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bCXP8zYuST7X"
   },
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "  \n",
    "  return np.maximum(0, Z), Z\n",
    "#these are the activation functions\n",
    "#while returning z we will call it the activation_cache\n",
    "#we will also return (A_prev, W, b) as linear_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jbE5T82aSVmJ"
   },
   "outputs": [],
   "source": [
    "def forward_prop(A_prev, W, b, activation):\n",
    " \n",
    "  \n",
    "  Z = np.dot(W, A_prev) + b\n",
    "  A, activation_cache = relu(Z)\n",
    "  linear_cache = (A_prev, W, b)\n",
    " \n",
    "  cache = (linear_cache, activation_cache)\n",
    " \n",
    "  return A, cache\n",
    " \n",
    "def L_nn_forward(X, parameters):\n",
    "  caches = []\n",
    "  L = len(parameters) // 2\n",
    "  #print(f'X shape: {X.shape}')\n",
    "  A = X.reshape(X.shape[0], -1)\n",
    " \n",
    "  for l in range(1, L+1): #check\n",
    "    A_prev = A\n",
    "    #print(f\"A_prev shape = {A_prev.shape}\")\n",
    "    W = parameters['W' + str(l)]\n",
    "    #print(f'W{l}: {W.shape}')\n",
    "    b = parameters['b' + str(l)]\n",
    "    #print(f'b{l}: {b.shape}')\n",
    "    A, cache = forward_prop(A_prev, W, b, 'relu')\n",
    "    #print(f'A: {A.shape}')\n",
    "    caches.append(cache)\n",
    "    \n",
    "  \n",
    "  return A, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mU0B4IrRSZlw"
   },
   "outputs": [],
   "source": [
    "parameters = initialize_parameters([7,5,7])\n",
    "X = np.array([1,2,3,4,5,6,7]).reshape(-1,1)\n",
    "A, caches = L_nn_forward(X, parameters) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOk-9oD77pzr",
    "outputId": "4ac43e7b-b38c-4aa5-8c9a-2a179a54c961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1) (5, 7) (5, 1)\n",
      "(5, 1) (7, 5) (7, 1)\n"
     ]
    }
   ],
   "source": [
    "linear = []\n",
    "activation = []\n",
    "for tup in caches:\n",
    "    linear.append(tup[0])\n",
    "    activation.append(tup[1])\n",
    "\n",
    "for x in linear:\n",
    "    print(x[0].shape, x[1].shape, x[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "g5NCmhMJSddU"
   },
   "outputs": [],
   "source": [
    "def Softmax(A_last):\n",
    "    for i in range(A_last.shape[1]):\n",
    "        # sum = 0\n",
    "        # for x in A_last[:,i]:\n",
    "        #     sum += np.exp(x)\n",
    "        for j in range(A_last.shape[0]):\n",
    "            A_last[j,i] = np.exp(A_last[j,i]) / np.sum(np.exp(A_last[:,i]))\n",
    "    return A_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9wCXdVZMTh7D"
   },
   "outputs": [],
   "source": [
    "A = Softmax(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zBKqSnyfTq5O"
   },
   "outputs": [],
   "source": [
    "#now for cost function\n",
    "Y = np.array([1,0,0,1,1,0,1])\n",
    "\n",
    "def compute_cost(A_last, Y):\n",
    "  m = Y.shape[1]\n",
    "\n",
    "  cost = (-1/m)*(np.sum(Y*np.log(A_last)))\n",
    "\n",
    "  return np.squeeze(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptxk9BCaUCD7",
    "outputId": "ecbf3e5b-a836-4bb2-c4ae-37b3ebf3dd9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.044931094244552\n"
     ]
    }
   ],
   "source": [
    "print(compute_cost(A, Y.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kMxQJU-GUIAJ"
   },
   "outputs": [],
   "source": [
    "#now for backward\n",
    "#dZ = dA * g'(Z)\n",
    "#this function calculates dZ, dA_prev, db and dW given dA\n",
    "#different for sigmoid and relu (2 extra functions)\n",
    "#linear_cache has the values = A_prev, W, b (used to compute Z)\n",
    "#activation_cache has the values Z\n",
    "\n",
    "def sigmoid_backward(dA, activation_cache):\n",
    "  Z = activation_cache\n",
    "  return dA*(Z)*(1-Z)\n",
    "\n",
    "def relu_backward(dA, activation_cache):\n",
    "  Z = activation_cache\n",
    "  diff = []\n",
    "  diff.append( 1 if Z.any()>0 else 0)\n",
    "  diff = np.array(diff)\n",
    "  return dA*diff\n",
    "\n",
    "\n",
    "def linear_acti_backward(dA, cache, activation):\n",
    "  #cache because we wil need the linear part and the activation part \n",
    "  #for the computation\n",
    "\n",
    "  linear_cache, activation_cache = cache #(A,W,b), Z\n",
    "  A_prev, W, b = linear_cache\n",
    "  m = A_prev.shape[1]\n",
    "\n",
    "  dZ = relu_backward(dA, activation_cache)\n",
    "  #print(f'dA: {dA.shape}, dZ: {dZ.shape}, A_prev: {A_prev.shape}')\n",
    "  dW = (1/m)*(np.dot(dZ, A_prev.T))\n",
    "  #print(f'dW: {dW.shape}')\n",
    "  db =  (1/m)*(np.sum(dZ, axis = 1, keepdims = True))\n",
    "  dA_prev = np.dot(W.T, dZ)\n",
    "  #print(f'dA_prev: {dA_prev.shape}')\n",
    "  return dA_prev, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BOGeh8j4IN3-"
   },
   "outputs": [],
   "source": [
    "def L_Backward(A_last, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) #number of layers\n",
    "    m = A_last.shape[1]\n",
    "    Y = Y.reshape(A_last.shape)\n",
    "\n",
    "    dA_last = -(Y/A_last) + ((1-Y)/(1-A_last))\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)],grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_acti_backward(dA_last, current_cache, 'relu')\n",
    "    #print(f'dA2: {dA_last.shape}, dA1: {grads[\"dA\" + str(L-1)].shape}')\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev = grads[\"dA\" + str(l+1)]\n",
    "        A = current_cache[0][0]\n",
    "        W = current_cache[0][1]\n",
    "        b = current_cache[0][2]\n",
    "        Z = current_cache[1][0]\n",
    "        dZ = relu_backward(dA_prev, Z)\n",
    "        grads[\"dW\" + str(l+1)] =  (1/dA_prev.shape[1])*(np.dot(dZ, A.T))\n",
    "        grads[\"db\" + str(l+1)] = (1/dA_prev.shape[1])*(np.sum(dZ, axis = 1, keepdims = True))\n",
    "        grads[\"dA\" + str(l)] = np.dot(W.T, dZ)\n",
    "\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "y_29895PoPYo"
   },
   "outputs": [],
   "source": [
    "grads = L_Backward(A, Y.reshape(-1,1), caches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7E_04DNGMAzr"
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "  L = len(parameters) // 2\n",
    "\n",
    "  for l in range(L):\n",
    "    parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - (learning_rate)*(grads[\"dW\" + str(l+1)])\n",
    "    parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate)*(grads[\"db\" + str(l+1)])\n",
    "\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "oUWicnxCMs1l"
   },
   "outputs": [],
   "source": [
    "#we will create a model in which we will execute all these gunctions\n",
    "#l is the number of layers and layers_dims is the dimension of the layers\n",
    "def deepnnmodel(X, Y,val, val_labels, layer_dims = [16, 26], batch_size = 500, learning_rate = 0.005, num_iterations =40):\n",
    "\n",
    "  np.random.seed(1)\n",
    "  costs = []\n",
    "  val_costs = []\n",
    "  parameters = initialize_parameters(layer_dims)\n",
    "\n",
    "  for i in range(num_iterations):\n",
    "\n",
    "    for j in range(0, X.shape[1], batch_size):\n",
    "      X_train = X[:,j:j+batch_size]\n",
    "      Y_train = Y[:,j:j+batch_size]\n",
    "      \n",
    "      A_last, caches = L_nn_forward(X_train, parameters)\n",
    "      A_last = Softmax(A_last)\n",
    "      cost = compute_cost(A_last, Y_train)\n",
    "\n",
    "      grads =  L_Backward(A_last, Y_train, caches)\n",
    "      #print(X_train)\n",
    "      #print(f\"\"\"A_last: {A_last}\n",
    "      #      cost: {cost}\n",
    "      #     grads: {grads}\"\"\")\n",
    "\n",
    "      parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "      #for val\n",
    "    val_x_train = val\n",
    "    val_y_train = val_labels\n",
    "    val_A_last, val_caches = L_nn_forward(val_x_train, parameters)\n",
    "    val_A_last = Softmax(val_A_last)\n",
    "    val_cost = compute_cost(val_A_last, val_y_train)\n",
    "\n",
    "\n",
    "    print(f'Epoch {i+1}: loss: {compute_cost(A_last, Y_train)}, val_loss = {compute_cost(val_A_last, val_y_train)}')\n",
    "    costs.append(compute_cost(A_last, Y_train))\n",
    "    val_costs.append(compute_cost(val_A_last, val_y_train))\n",
    "    \n",
    "  return parameters, costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dW1xI2SVM-X6",
    "outputId": "1f233e0e-7ad1-4cee-8f49-ac12b926c3b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss: 3.0454581028112235, val_loss = 3.0459110478827913\n",
      "Epoch 2: loss: 2.9547331637847574, val_loss = 2.9608240294785815\n",
      "Epoch 3: loss: 2.90923924032198, val_loss = 2.917629194726831\n",
      "Epoch 4: loss: 2.8794492692893674, val_loss = 2.8891672182472816\n",
      "Epoch 5: loss: 2.8568386743736083, val_loss = 2.8668792650093473\n",
      "Epoch 6: loss: 2.838288479222592, val_loss = 2.8478208708269266\n",
      "Epoch 7: loss: 2.821890678522472, val_loss = 2.830567799492097\n",
      "Epoch 8: loss: 2.806181063543579, val_loss = 2.814764275718791\n",
      "Epoch 9: loss: 2.7915883736372553, val_loss = 2.8001550473070433\n",
      "Epoch 10: loss: 2.7779932850734355, val_loss = 2.7866116423471574\n",
      "Epoch 11: loss: 2.7653727986962524, val_loss = 2.773879234448845\n",
      "Epoch 12: loss: 2.753784585536644, val_loss = 2.7620971771123277\n",
      "Epoch 13: loss: 2.74310854225081, val_loss = 2.751015791890723\n",
      "Epoch 14: loss: 2.7329017615991633, val_loss = 2.7406740083474337\n",
      "Epoch 15: loss: 2.7234798545538523, val_loss = 2.7310938914115743\n",
      "Epoch 16: loss: 2.7147237130828343, val_loss = 2.7222030007062195\n",
      "Epoch 17: loss: 2.7066592449682756, val_loss = 2.713878415149141\n",
      "Epoch 18: loss: 2.699229000828748, val_loss = 2.7059931641020407\n",
      "Epoch 19: loss: 2.692261702317898, val_loss = 2.698502672708622\n",
      "Epoch 20: loss: 2.6854728909760683, val_loss = 2.6914306451001555\n",
      "Epoch 21: loss: 2.6790494732153176, val_loss = 2.684718871894977\n",
      "Epoch 22: loss: 2.6729549904538903, val_loss = 2.6783082168315535\n",
      "Epoch 23: loss: 2.667016683552741, val_loss = 2.6721844911723736\n",
      "Epoch 24: loss: 2.661214208114276, val_loss = 2.666366350887467\n",
      "Epoch 25: loss: 2.6557537338876056, val_loss = 2.660810684335356\n",
      "Epoch 26: loss: 2.6506215798701533, val_loss = 2.65547765927488\n",
      "Epoch 27: loss: 2.645725315118119, val_loss = 2.6503256390965446\n",
      "Epoch 28: loss: 2.641137344721134, val_loss = 2.6453945257357137\n",
      "Epoch 29: loss: 2.636804251256038, val_loss = 2.640732681079865\n",
      "Epoch 30: loss: 2.6324824611618554, val_loss = 2.6363341195036054\n",
      "Epoch 31: loss: 2.6283217446402594, val_loss = 2.632171844036382\n",
      "Epoch 32: loss: 2.6245010557825603, val_loss = 2.628127780120723\n",
      "Epoch 33: loss: 2.620790081411301, val_loss = 2.6243052304136083\n",
      "Epoch 34: loss: 2.6173646456427107, val_loss = 2.6208283370934278\n",
      "Epoch 35: loss: 2.614258958560568, val_loss = 2.617622893516924\n",
      "Epoch 36: loss: 2.6113173801875798, val_loss = 2.614653054965455\n",
      "Epoch 37: loss: 2.608622447340538, val_loss = 2.611885728384837\n",
      "Epoch 38: loss: 2.606060123446727, val_loss = 2.6092562590728603\n",
      "Epoch 39: loss: 2.6036167541020876, val_loss = 2.6069062102937015\n",
      "Epoch 40: loss: 2.6013671367912083, val_loss = 2.604825888703537\n"
     ]
    }
   ],
   "source": [
    "params, cos = deepnnmodel(train, labels, val, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "iBiWfeFvVuBe",
    "outputId": "7f1b2e2b-07e0-4559-aeaa-17e167d1ccbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "0         3      5      4     4      2      7      8      5      4      7   \n",
       "1         4      6      6     6      4      7      5      4      4      8   \n",
       "2         3      7      4     5      3      8      7      7      6      7   \n",
       "3         3      6      4     4      2      5     12      7      3     12   \n",
       "4         3      7      4     5      3      7      6      6      6      6   \n",
       "...     ...    ...    ...   ...    ...    ...    ...    ...    ...    ...   \n",
       "3495      2      3      4     1      2      6      8      1      6     10   \n",
       "3496      6      9      8     7      5      9      8      1      8     14   \n",
       "3497      4     11      6     8      6      6     10      4      5     10   \n",
       "3498      1      0      2     1      0      7      7     11      0      5   \n",
       "3499      4      7      5     5      2      7      3     14      6      7   \n",
       "\n",
       "      x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
       "0         7      7      6      9      2      5  \n",
       "1         3      7      3      7      4      8  \n",
       "2         6      7      3      8      4      7  \n",
       "3         6      3      1     10      4      7  \n",
       "4         5      9      2      9      6     11  \n",
       "...     ...    ...    ...    ...    ...    ...  \n",
       "3495      6      9      3      8      2      8  \n",
       "3496      5      6      5      8      5      9  \n",
       "3497      9      4      4     10      4      7  \n",
       "3498      6      8      4      8      0      8  \n",
       "3499     13      8      3      9      0      8  \n",
       "\n",
       "[3500 rows x 16 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =  pd.read_csv('test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "8JJBa-EXbjO4"
   },
   "outputs": [],
   "source": [
    "test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "TKqDYI5ab5Sc"
   },
   "outputs": [],
   "source": [
    "test = test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "O0nSF7ntb6Br"
   },
   "outputs": [],
   "source": [
    "W1 = params[\"W1\"]\n",
    "b1 = params[\"b1\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "k8dYFOntb_eR"
   },
   "outputs": [],
   "source": [
    "A1 = np.dot(W1, test) + b1\n",
    "A1, _ = relu(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gzp66zxgdtsf",
    "outputId": "95346ddf-715b-44a5-8141-84ca34cede63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 3500)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = Softmax(A1)\n",
    "A1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ScjREurNduqV"
   },
   "outputs": [],
   "source": [
    "maxi = []\n",
    "for i in range(A1.shape[1]):\n",
    "    maxi.append(A1[:,i].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "MzV_k5NDehrE"
   },
   "outputs": [],
   "source": [
    "letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "L82_avXqe2Cx"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in maxi:\n",
    "    preds.append(letters[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TYPiZ-PivEZi",
    "outputId": "ede78153-8110-4831-f7a6-82ddaa51a138"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " 'G',\n",
       " 'C',\n",
       " 'P',\n",
       " 'G',\n",
       " 'E',\n",
       " 'V',\n",
       " 'H',\n",
       " 'Q',\n",
       " 'C',\n",
       " 'C',\n",
       " 'G',\n",
       " 'Q',\n",
       " 'H',\n",
       " 'G',\n",
       " 'U',\n",
       " 'T',\n",
       " 'G',\n",
       " 'G',\n",
       " 'Q',\n",
       " 'G',\n",
       " 'T',\n",
       " 'T',\n",
       " 'Z',\n",
       " 'E',\n",
       " 'Q',\n",
       " 'Z',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'T',\n",
       " 'E',\n",
       " 'G',\n",
       " 'T',\n",
       " 'G',\n",
       " 'G',\n",
       " 'E',\n",
       " 'E',\n",
       " 'H',\n",
       " 'C',\n",
       " 'G',\n",
       " 'G',\n",
       " 'E',\n",
       " 'C',\n",
       " 'Q',\n",
       " 'E',\n",
       " 'G',\n",
       " 'Z',\n",
       " 'G',\n",
       " 'T',\n",
       " 'E',\n",
       " 'E',\n",
       " 'C',\n",
       " 'G',\n",
       " 'Z',\n",
       " 'G',\n",
       " 'T',\n",
       " 'H',\n",
       " 'G',\n",
       " 'H',\n",
       " 'E',\n",
       " 'H',\n",
       " 'U',\n",
       " 'C',\n",
       " 'E',\n",
       " 'H',\n",
       " 'Z',\n",
       " 'G',\n",
       " 'Y',\n",
       " 'T',\n",
       " 'Q',\n",
       " 'T',\n",
       " 'H',\n",
       " 'T',\n",
       " 'T',\n",
       " 'T',\n",
       " 'E',\n",
       " 'C',\n",
       " 'H',\n",
       " 'V',\n",
       " 'Q',\n",
       " 'T',\n",
       " 'Q',\n",
       " 'Q',\n",
       " 'V',\n",
       " 'E',\n",
       " 'C',\n",
       " 'Q',\n",
       " 'C',\n",
       " 'E',\n",
       " 'E',\n",
       " 'E',\n",
       " 'G',\n",
       " 'G',\n",
       " 'H',\n",
       " 'E',\n",
       " 'H',\n",
       " 'H',\n",
       " 'E',\n",
       " 'G',\n",
       " 'E',\n",
       " 'V',\n",
       " 'G',\n",
       " 'T',\n",
       " 'C',\n",
       " 'G',\n",
       " 'E',\n",
       " 'G',\n",
       " 'Q',\n",
       " 'G',\n",
       " 'H',\n",
       " 'H',\n",
       " 'E',\n",
       " 'Z',\n",
       " 'H',\n",
       " 'E',\n",
       " 'E',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'H',\n",
       " 'G',\n",
       " 'T',\n",
       " 'Z',\n",
       " 'V',\n",
       " 'C',\n",
       " 'G',\n",
       " 'G',\n",
       " 'C',\n",
       " 'E',\n",
       " 'E',\n",
       " 'C',\n",
       " 'G',\n",
       " 'G',\n",
       " 'G',\n",
       " 'E',\n",
       " 'E',\n",
       " 'E',\n",
       " 'Q',\n",
       " 'Q',\n",
       " 'G',\n",
       " 'M',\n",
       " 'E',\n",
       " 'U',\n",
       " 'G',\n",
       " 'K',\n",
       " 'Q',\n",
       " 'G',\n",
       " 'Q',\n",
       " 'E',\n",
       " 'E',\n",
       " 'G',\n",
       " 'T',\n",
       " 'C',\n",
       " 'C',\n",
       " 'G',\n",
       " 'E',\n",
       " 'E',\n",
       " 'C',\n",
       " 'E',\n",
       " 'V',\n",
       " 'G',\n",
       " 'C',\n",
       " 'C',\n",
       " 'E',\n",
       " 'E',\n",
       " 'C',\n",
       " 'V',\n",
       " 'T',\n",
       " 'H',\n",
       " 'Q',\n",
       " 'E',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'G',\n",
       " 'C',\n",
       " 'G',\n",
       " 'Q',\n",
       " 'V',\n",
       " 'E',\n",
       " 'G',\n",
       " 'C',\n",
       " 'M',\n",
       " 'E',\n",
       " 'Q',\n",
       " 'T',\n",
       " 'V',\n",
       " 'G',\n",
       " 'H',\n",
       " 'E',\n",
       " 'V',\n",
       " 'Q',\n",
       " 'G',\n",
       " 'V',\n",
       " 'H',\n",
       " 'G',\n",
       " 'Q',\n",
       " 'T',\n",
       " 'Q',\n",
       " 'H']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "AZ5B8J5xjpR7"
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"ID\": list(range(1,len(preds)+1)),\n",
    "                           \"Label\": preds})\n",
    "predictions.to_csv(\"test_predictions\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deep_NN_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
