{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FDxA_mqCgds6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCWMvM-dhEcl",
    "outputId": "bc02f0d8-55f5-4222-ae5d-3ad36dc33e59"
   },
   "outputs": [],
   "source": [
    "device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "rIPxT8h0hHrH",
    "outputId": "c2c12327-2c66-46e4-82ce-d63aed649432"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0        1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2        1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3        4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "41996    1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "41997    7.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "41998    6.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "41999    9.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "41996     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "41997     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "41998     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "41999     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0           0.0       0.0       0.0       0.0       0.0  \n",
       "1           0.0       0.0       0.0       0.0       0.0  \n",
       "2           0.0       0.0       0.0       0.0       0.0  \n",
       "3           0.0       0.0       0.0       0.0       0.0  \n",
       "4           0.0       0.0       0.0       0.0       0.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995       0.0       0.0       0.0       0.0       0.0  \n",
       "41996       0.0       0.0       0.0       0.0       0.0  \n",
       "41997       0.0       0.0       0.0       0.0       0.0  \n",
       "41998       0.0       0.0       0.0       0.0       0.0  \n",
       "41999       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', dtype = np.float32)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fullha5mmDn8"
   },
   "outputs": [],
   "source": [
    "targets = train.pop('label').values\n",
    "features = train.values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RBt6TkVpmol8"
   },
   "outputs": [],
   "source": [
    "features_train, features_test, targets_train, targets_test = train_test_split(features,\n",
    "                                                                              targets,\n",
    "                                                                              test_size = 12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qZ9cHCcinNfT"
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(features_train)\n",
    "X_test = torch.from_numpy(features_test)\n",
    "Y_train = torch.from_numpy(targets_train)\n",
    "Y_test = torch.from_numpy(targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-b-b62BboKo5",
    "outputId": "943d90b7-66e0-41ba-c8c9-55fa68a50991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30000, 784]) torch.Size([30000]) torch.Size([12000, 784]) torch.Size([12000])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "usIEd4Lxohm4",
    "outputId": "28edc6aa-cee8-41cd-c496-48f757302c9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2446a621580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1,:].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7tX8S5z-pUGo"
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "      self.relu = nn.ReLU(inplace = True)\n",
    "      self.pool1 = nn.AvgPool2d(kernel_size=2)\n",
    "      self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3)\n",
    "      self.pool2 = nn.AvgPool2d(kernel_size=2)\n",
    "      self.fc1 = nn.Linear(in_features = 16*5*5, out_features = 120).cuda()\n",
    "      self.fc2 = nn.Linear(in_features = 120, out_features = 90).cuda()\n",
    "      self.fc3 = nn.Linear(in_features = 90,out_features = 10).cuda()\n",
    "      self.do = nn.Dropout2d(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.conv1(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.pool1(x)\n",
    "      x = self.conv2(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.do(x) \n",
    "      x = self.pool2(x)\n",
    "      x = x.view(x.size(0), -1)\n",
    "      x = self.fc1(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.do(x)\n",
    "      x = self.fc2(x)\n",
    "      y = self.relu(x)\n",
    "      return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3gC0QaKHqeVa"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "batch_size = 100\n",
    "n_iter = int(len(X_train)/batch_size) + 1\n",
    "n_epochs = 500\n",
    "\n",
    "train = TensorDataset(X_train, Y_train)\n",
    "test = TensorDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "model = LeNet().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    probs = F.softmax(outputs, dim=1)\n",
    "    max_probs, preds = torch.max(probs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item()/len(preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "vnynvvnWsOhd",
    "outputId": "eec21f1c-6827-4aab-852e-89fd59efeb02",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.3833608627319336, accuracy = 0.8899999856948853, val_loss = 0.4519517421722412, val_acc = 0.8600833415985107\n",
      "Epoch 2: Loss = 0.35257256031036377, accuracy = 0.9100000262260437, val_loss = 0.31196117401123047, val_acc = 0.9066666960716248\n",
      "Epoch 3: Loss = 0.2585313022136688, accuracy = 0.9300000071525574, val_loss = 0.24457049369812012, val_acc = 0.9273333549499512\n",
      "Epoch 4: Loss = 0.2008364349603653, accuracy = 0.949999988079071, val_loss = 0.2061314433813095, val_acc = 0.9351666569709778\n",
      "Epoch 5: Loss = 0.17222629487514496, accuracy = 0.949999988079071, val_loss = 0.1743098497390747, val_acc = 0.9455833435058594\n",
      "Epoch 6: Loss = 0.2104608416557312, accuracy = 0.9200000166893005, val_loss = 0.16375572979450226, val_acc = 0.9489166736602783\n",
      "Epoch 7: Loss = 0.18668504059314728, accuracy = 0.9399999976158142, val_loss = 0.14456836879253387, val_acc = 0.9583333134651184\n",
      "Epoch 8: Loss = 0.15715095400810242, accuracy = 0.9599999785423279, val_loss = 0.13897892832756042, val_acc = 0.9581666588783264\n",
      "Epoch 9: Loss = 0.11623143404722214, accuracy = 0.949999988079071, val_loss = 0.13538414239883423, val_acc = 0.9594166874885559\n",
      "Epoch 10: Loss = 0.14542746543884277, accuracy = 0.9599999785423279, val_loss = 0.12231528759002686, val_acc = 0.9636666774749756\n",
      "Epoch 11: Loss = 0.11098892241716385, accuracy = 0.9700000286102295, val_loss = 0.12273236364126205, val_acc = 0.9624999761581421\n",
      "Epoch 12: Loss = 0.20324251055717468, accuracy = 0.9599999785423279, val_loss = 0.11581435799598694, val_acc = 0.9648333191871643\n",
      "Epoch 13: Loss = 0.2066134512424469, accuracy = 0.949999988079071, val_loss = 0.11127078533172607, val_acc = 0.9661666750907898\n",
      "Epoch 14: Loss = 0.14254812896251678, accuracy = 0.9700000286102295, val_loss = 0.11347401887178421, val_acc = 0.965666651725769\n",
      "Epoch 15: Loss = 0.15465880930423737, accuracy = 0.9599999785423279, val_loss = 0.10106012970209122, val_acc = 0.968666672706604\n",
      "Epoch 16: Loss = 0.11118516325950623, accuracy = 0.9800000190734863, val_loss = 0.10019566118717194, val_acc = 0.968999981880188\n",
      "Epoch 17: Loss = 0.1198481097817421, accuracy = 0.9599999785423279, val_loss = 0.10268848389387131, val_acc = 0.9695833325386047\n",
      "Epoch 18: Loss = 0.1650494635105133, accuracy = 0.9599999785423279, val_loss = 0.09920404851436615, val_acc = 0.971833348274231\n",
      "Epoch 19: Loss = 0.11584312468767166, accuracy = 0.9800000190734863, val_loss = 0.0985979437828064, val_acc = 0.9706666469573975\n",
      "Epoch 20: Loss = 0.07733781635761261, accuracy = 0.9900000095367432, val_loss = 0.0904703438282013, val_acc = 0.9739166498184204\n",
      "Epoch 21: Loss = 0.09014419466257095, accuracy = 0.9700000286102295, val_loss = 0.09334126859903336, val_acc = 0.9715833067893982\n",
      "Epoch 22: Loss = 0.14184963703155518, accuracy = 0.9800000190734863, val_loss = 0.08957727253437042, val_acc = 0.9746666550636292\n",
      "Epoch 23: Loss = 0.08399737626314163, accuracy = 0.9800000190734863, val_loss = 0.09407688677310944, val_acc = 0.9727500081062317\n",
      "Epoch 24: Loss = 0.1528378129005432, accuracy = 0.9700000286102295, val_loss = 0.08531666547060013, val_acc = 0.9755833148956299\n",
      "Epoch 25: Loss = 0.13339191675186157, accuracy = 0.9599999785423279, val_loss = 0.08748938143253326, val_acc = 0.9747499823570251\n",
      "Epoch 26: Loss = 0.14262837171554565, accuracy = 0.9700000286102295, val_loss = 0.08914393186569214, val_acc = 0.9745000004768372\n",
      "Epoch 27: Loss = 0.10720347613096237, accuracy = 0.9800000190734863, val_loss = 0.09573221951723099, val_acc = 0.9744166731834412\n",
      "Epoch 28: Loss = 0.09609420597553253, accuracy = 0.9900000095367432, val_loss = 0.08964404463768005, val_acc = 0.9753333330154419\n",
      "Epoch 29: Loss = 0.06350365281105042, accuracy = 0.9700000286102295, val_loss = 0.08289685845375061, val_acc = 0.9755833148956299\n",
      "Epoch 30: Loss = 0.1181827038526535, accuracy = 0.9599999785423279, val_loss = 0.09006499499082565, val_acc = 0.9762499928474426\n",
      "Epoch 31: Loss = 0.13809996843338013, accuracy = 0.9599999785423279, val_loss = 0.0851656123995781, val_acc = 0.9750833511352539\n",
      "Epoch 32: Loss = 0.1010999083518982, accuracy = 0.9700000286102295, val_loss = 0.08129125833511353, val_acc = 0.9754999876022339\n",
      "Epoch 33: Loss = 0.14392586052417755, accuracy = 0.9800000190734863, val_loss = 0.08780980110168457, val_acc = 0.9756666421890259\n",
      "Epoch 34: Loss = 0.11823480576276779, accuracy = 0.9900000095367432, val_loss = 0.08097917586565018, val_acc = 0.9774166941642761\n",
      "Epoch 35: Loss = 0.08451022207736969, accuracy = 0.9700000286102295, val_loss = 0.08574333041906357, val_acc = 0.9767500162124634\n",
      "Epoch 36: Loss = 0.13905403017997742, accuracy = 0.949999988079071, val_loss = 0.08491101861000061, val_acc = 0.9773333072662354\n",
      "Epoch 37: Loss = 0.09726551920175552, accuracy = 0.949999988079071, val_loss = 0.0795135572552681, val_acc = 0.9783333539962769\n",
      "Epoch 38: Loss = 0.054976314306259155, accuracy = 0.9700000286102295, val_loss = 0.08472064882516861, val_acc = 0.9761666655540466\n",
      "Epoch 39: Loss = 0.1375342756509781, accuracy = 0.9800000190734863, val_loss = 0.07879852503538132, val_acc = 0.9784166812896729\n",
      "Epoch 40: Loss = 0.05271529778838158, accuracy = 0.9800000190734863, val_loss = 0.08251482993364334, val_acc = 0.9785833358764648\n",
      "Epoch 41: Loss = 0.06727882474660873, accuracy = 0.9800000190734863, val_loss = 0.081287682056427, val_acc = 0.9786666631698608\n",
      "Epoch 42: Loss = 0.027497529983520508, accuracy = 0.9900000095367432, val_loss = 0.08024001866579056, val_acc = 0.9779999852180481\n",
      "Epoch 43: Loss = 0.06493860483169556, accuracy = 0.9800000190734863, val_loss = 0.08243648707866669, val_acc = 0.9775833487510681\n",
      "Epoch 44: Loss = 0.09870824962854385, accuracy = 0.9599999785423279, val_loss = 0.08011189103126526, val_acc = 0.9796666502952576\n",
      "Epoch 45: Loss = 0.06487179547548294, accuracy = 0.9800000190734863, val_loss = 0.08170106261968613, val_acc = 0.9796666502952576\n",
      "Epoch 46: Loss = 0.0859178751707077, accuracy = 0.9399999976158142, val_loss = 0.08371621370315552, val_acc = 0.9775000214576721\n",
      "Epoch 47: Loss = 0.055811505764722824, accuracy = 0.9900000095367432, val_loss = 0.08520200848579407, val_acc = 0.9772499799728394\n",
      "Epoch 48: Loss = 0.08064363151788712, accuracy = 0.9900000095367432, val_loss = 0.08128740638494492, val_acc = 0.9793333411216736\n",
      "Epoch 49: Loss = 0.0499572791159153, accuracy = 0.9800000190734863, val_loss = 0.07741182297468185, val_acc = 0.9784166812896729\n",
      "Epoch 50: Loss = 0.03877146542072296, accuracy = 0.9900000095367432, val_loss = 0.07588187605142593, val_acc = 0.9797499775886536\n",
      "Epoch 51: Loss = 0.03867223113775253, accuracy = 0.9900000095367432, val_loss = 0.08542972803115845, val_acc = 0.9797499775886536\n",
      "Epoch 52: Loss = 0.13421277701854706, accuracy = 0.9599999785423279, val_loss = 0.08258575201034546, val_acc = 0.9787499904632568\n",
      "Epoch 53: Loss = 0.03339596092700958, accuracy = 0.9900000095367432, val_loss = 0.07759413868188858, val_acc = 0.9796666502952576\n",
      "Epoch 54: Loss = 0.0695124939084053, accuracy = 0.949999988079071, val_loss = 0.08029896020889282, val_acc = 0.9788333177566528\n",
      "Epoch 55: Loss = 0.013517319224774837, accuracy = 1.0, val_loss = 0.08404963463544846, val_acc = 0.9797499775886536\n",
      "Epoch 56: Loss = 0.04267624393105507, accuracy = 0.9800000190734863, val_loss = 0.08477349579334259, val_acc = 0.9786666631698608\n",
      "Epoch 57: Loss = 0.033963631838560104, accuracy = 0.9900000095367432, val_loss = 0.0795593410730362, val_acc = 0.9804999828338623\n",
      "Epoch 58: Loss = 0.02978655882179737, accuracy = 1.0, val_loss = 0.07517638802528381, val_acc = 0.9803333282470703\n",
      "Epoch 59: Loss = 0.04645266383886337, accuracy = 0.9700000286102295, val_loss = 0.07536806911230087, val_acc = 0.9799166917800903\n",
      "Epoch 60: Loss = 0.017962036654353142, accuracy = 0.9900000095367432, val_loss = 0.0808194950222969, val_acc = 0.9785833358764648\n",
      "Epoch 61: Loss = 0.052035264670848846, accuracy = 0.9900000095367432, val_loss = 0.07868747413158417, val_acc = 0.9808333516120911\n",
      "Epoch 62: Loss = 0.06055457517504692, accuracy = 0.9700000286102295, val_loss = 0.07840555161237717, val_acc = 0.9805833101272583\n",
      "Epoch 63: Loss = 0.027333687990903854, accuracy = 0.9900000095367432, val_loss = 0.08330868184566498, val_acc = 0.9784166812896729\n",
      "Epoch 64: Loss = 0.05332937836647034, accuracy = 0.9800000190734863, val_loss = 0.07264155894517899, val_acc = 0.9804999828338623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Loss = 0.02357371151447296, accuracy = 0.9900000095367432, val_loss = 0.07978016883134842, val_acc = 0.9807500243186951\n",
      "Epoch 66: Loss = 0.026066260412335396, accuracy = 0.9900000095367432, val_loss = 0.08390568941831589, val_acc = 0.9797499775886536\n",
      "Epoch 67: Loss = 0.047158654779195786, accuracy = 0.9800000190734863, val_loss = 0.08221184462308884, val_acc = 0.9805833101272583\n",
      "Epoch 68: Loss = 0.03431112691760063, accuracy = 0.9800000190734863, val_loss = 0.07376948744058609, val_acc = 0.9815833568572998\n",
      "Epoch 69: Loss = 0.038765452802181244, accuracy = 0.9900000095367432, val_loss = 0.07956971973180771, val_acc = 0.9807500243186951\n",
      "Epoch 70: Loss = 0.025506598874926567, accuracy = 0.9900000095367432, val_loss = 0.07491985708475113, val_acc = 0.9817500114440918\n",
      "Epoch 71: Loss = 0.01852736435830593, accuracy = 0.9900000095367432, val_loss = 0.08026167005300522, val_acc = 0.9810000061988831\n",
      "Epoch 72: Loss = 0.05239706113934517, accuracy = 0.9700000286102295, val_loss = 0.07435422390699387, val_acc = 0.981083333492279\n",
      "Epoch 73: Loss = 0.03337094932794571, accuracy = 0.9900000095367432, val_loss = 0.07712068408727646, val_acc = 0.9803333282470703\n",
      "Epoch 74: Loss = 0.02047252655029297, accuracy = 0.9900000095367432, val_loss = 0.07199046015739441, val_acc = 0.9824166893959045\n",
      "Epoch 75: Loss = 0.021519936621189117, accuracy = 0.9900000095367432, val_loss = 0.07448907196521759, val_acc = 0.9793333411216736\n",
      "Epoch 76: Loss = 0.018447767943143845, accuracy = 1.0, val_loss = 0.07561149448156357, val_acc = 0.9810000061988831\n",
      "Epoch 77: Loss = 0.016629168763756752, accuracy = 1.0, val_loss = 0.07930178195238113, val_acc = 0.9810000061988831\n",
      "Epoch 78: Loss = 0.07281854748725891, accuracy = 0.9800000190734863, val_loss = 0.0849078819155693, val_acc = 0.9785000085830688\n",
      "Epoch 79: Loss = 0.043958693742752075, accuracy = 0.9900000095367432, val_loss = 0.07367314398288727, val_acc = 0.9818333387374878\n",
      "Epoch 80: Loss = 0.06967676430940628, accuracy = 0.9800000190734863, val_loss = 0.08045116811990738, val_acc = 0.981249988079071\n",
      "Epoch 81: Loss = 0.0518760159611702, accuracy = 0.9800000190734863, val_loss = 0.08551102876663208, val_acc = 0.9803333282470703\n",
      "Epoch 82: Loss = 0.016137506812810898, accuracy = 1.0, val_loss = 0.07981203496456146, val_acc = 0.9805833101272583\n",
      "Epoch 83: Loss = 0.041415225714445114, accuracy = 0.9900000095367432, val_loss = 0.08259246498346329, val_acc = 0.9804999828338623\n",
      "Epoch 84: Loss = 0.010634711012244225, accuracy = 0.9900000095367432, val_loss = 0.08525610715150833, val_acc = 0.9798333048820496\n",
      "Epoch 85: Loss = 0.05467306450009346, accuracy = 0.9800000190734863, val_loss = 0.08575677126646042, val_acc = 0.981249988079071\n",
      "Epoch 86: Loss = 0.05395679920911789, accuracy = 0.9800000190734863, val_loss = 0.07702313363552094, val_acc = 0.9810000061988831\n",
      "Epoch 87: Loss = 0.015608188696205616, accuracy = 0.9900000095367432, val_loss = 0.07651661336421967, val_acc = 0.9821666479110718\n",
      "Epoch 88: Loss = 0.02615646831691265, accuracy = 0.9900000095367432, val_loss = 0.0890619307756424, val_acc = 0.9821666479110718\n",
      "Epoch 89: Loss = 0.021781664341688156, accuracy = 0.9800000190734863, val_loss = 0.07420734316110611, val_acc = 0.9825833439826965\n",
      "Epoch 90: Loss = 0.03534223884344101, accuracy = 0.9900000095367432, val_loss = 0.08069531619548798, val_acc = 0.9815000295639038\n",
      "Epoch 91: Loss = 0.07405834645032883, accuracy = 0.9700000286102295, val_loss = 0.07680836319923401, val_acc = 0.984083354473114\n",
      "Epoch 92: Loss = 0.020936641842126846, accuracy = 0.9900000095367432, val_loss = 0.08463841676712036, val_acc = 0.9801666736602783\n",
      "Epoch 93: Loss = 0.01898481696844101, accuracy = 1.0, val_loss = 0.07889389991760254, val_acc = 0.9819999933242798\n",
      "Epoch 94: Loss = 0.007882842794060707, accuracy = 1.0, val_loss = 0.08083852380514145, val_acc = 0.9805833101272583\n",
      "Epoch 95: Loss = 0.0186619833111763, accuracy = 0.9900000095367432, val_loss = 0.07387920469045639, val_acc = 0.9828333258628845\n",
      "Epoch 96: Loss = 0.0437425896525383, accuracy = 0.9800000190734863, val_loss = 0.07160328328609467, val_acc = 0.9826666712760925\n",
      "Epoch 97: Loss = 0.025151889771223068, accuracy = 0.9800000190734863, val_loss = 0.08015009760856628, val_acc = 0.9838333129882812\n",
      "Epoch 98: Loss = 0.015694335103034973, accuracy = 1.0, val_loss = 0.07844390720129013, val_acc = 0.981333315372467\n",
      "Epoch 99: Loss = 0.013003090396523476, accuracy = 0.9900000095367432, val_loss = 0.08311167359352112, val_acc = 0.9801666736602783\n",
      "Epoch 100: Loss = 0.03475570306181908, accuracy = 0.9800000190734863, val_loss = 0.08566536754369736, val_acc = 0.981416642665863\n",
      "Epoch 101: Loss = 0.011368665844202042, accuracy = 1.0, val_loss = 0.08199381828308105, val_acc = 0.9821666479110718\n",
      "Epoch 102: Loss = 0.05425380542874336, accuracy = 0.9800000190734863, val_loss = 0.08177058398723602, val_acc = 0.9794166684150696\n",
      "Epoch 103: Loss = 0.01836061291396618, accuracy = 1.0, val_loss = 0.0751347467303276, val_acc = 0.9833333492279053\n",
      "Epoch 104: Loss = 0.018614085391163826, accuracy = 0.9900000095367432, val_loss = 0.08184783160686493, val_acc = 0.9809166789054871\n",
      "Epoch 105: Loss = 0.024580679833889008, accuracy = 0.9900000095367432, val_loss = 0.08745212107896805, val_acc = 0.9809166789054871\n",
      "Epoch 106: Loss = 0.045818209648132324, accuracy = 0.9900000095367432, val_loss = 0.07953844964504242, val_acc = 0.9819999933242798\n",
      "Epoch 107: Loss = 0.10982891917228699, accuracy = 0.9800000190734863, val_loss = 0.07260139286518097, val_acc = 0.9825833439826965\n",
      "Epoch 108: Loss = 0.005248240195214748, accuracy = 1.0, val_loss = 0.08370634913444519, val_acc = 0.9809166789054871\n",
      "Epoch 109: Loss = 0.007847634144127369, accuracy = 1.0, val_loss = 0.07556375861167908, val_acc = 0.9826666712760925\n",
      "Epoch 110: Loss = 0.01990075595676899, accuracy = 0.9900000095367432, val_loss = 0.07908342778682709, val_acc = 0.9819166660308838\n",
      "Epoch 111: Loss = 0.0108341621235013, accuracy = 1.0, val_loss = 0.0868484228849411, val_acc = 0.9789166450500488\n",
      "Epoch 112: Loss = 0.0349537655711174, accuracy = 0.9800000190734863, val_loss = 0.07419459521770477, val_acc = 0.9829166531562805\n",
      "Epoch 113: Loss = 0.0013158452929928899, accuracy = 1.0, val_loss = 0.0730898305773735, val_acc = 0.9832500219345093\n",
      "Epoch 114: Loss = 0.0037262553814798594, accuracy = 1.0, val_loss = 0.08491392433643341, val_acc = 0.9825000166893005\n",
      "Epoch 115: Loss = 0.05345059558749199, accuracy = 0.9800000190734863, val_loss = 0.07605373114347458, val_acc = 0.98458331823349\n",
      "Epoch 116: Loss = 0.0038029837887734175, accuracy = 1.0, val_loss = 0.08532107621431351, val_acc = 0.981249988079071\n",
      "Epoch 117: Loss = 0.0138842249289155, accuracy = 1.0, val_loss = 0.07670195400714874, val_acc = 0.9835833311080933\n",
      "Epoch 118: Loss = 0.04933830350637436, accuracy = 0.9900000095367432, val_loss = 0.07756750285625458, val_acc = 0.9833333492279053\n",
      "Epoch 119: Loss = 0.011683892458677292, accuracy = 1.0, val_loss = 0.07970911264419556, val_acc = 0.9821666479110718\n",
      "Epoch 120: Loss = 0.009131320752203465, accuracy = 1.0, val_loss = 0.08705425262451172, val_acc = 0.9833333492279053\n",
      "Epoch 121: Loss = 0.012453099712729454, accuracy = 1.0, val_loss = 0.082957923412323, val_acc = 0.9825833439826965\n",
      "Epoch 122: Loss = 0.007416706066578627, accuracy = 1.0, val_loss = 0.09454119950532913, val_acc = 0.9828333258628845\n",
      "Epoch 123: Loss = 0.012684137560427189, accuracy = 0.9900000095367432, val_loss = 0.07425190508365631, val_acc = 0.9833333492279053\n",
      "Epoch 124: Loss = 0.007654947694391012, accuracy = 1.0, val_loss = 0.08574329316616058, val_acc = 0.981333315372467\n",
      "Epoch 125: Loss = 0.03526917099952698, accuracy = 0.9900000095367432, val_loss = 0.08378326892852783, val_acc = 0.9822499752044678\n",
      "Epoch 126: Loss = 0.033136121928691864, accuracy = 0.9800000190734863, val_loss = 0.08760365843772888, val_acc = 0.9825833439826965\n",
      "Epoch 127: Loss = 0.013350361958146095, accuracy = 0.9900000095367432, val_loss = 0.08790522068738937, val_acc = 0.9823333621025085\n",
      "Epoch 128: Loss = 0.01919514685869217, accuracy = 0.9900000095367432, val_loss = 0.07810606062412262, val_acc = 0.9819166660308838\n",
      "Epoch 129: Loss = 0.008549470454454422, accuracy = 1.0, val_loss = 0.07572003453969955, val_acc = 0.9834166765213013\n",
      "Epoch 130: Loss = 0.0435531884431839, accuracy = 0.9800000190734863, val_loss = 0.08855501562356949, val_acc = 0.9825000166893005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131: Loss = 0.03143944963812828, accuracy = 0.9900000095367432, val_loss = 0.07663457095623016, val_acc = 0.9825000166893005\n",
      "Epoch 132: Loss = 0.046414680778980255, accuracy = 0.9900000095367432, val_loss = 0.07355044782161713, val_acc = 0.984083354473114\n",
      "Epoch 133: Loss = 0.0025621599052101374, accuracy = 1.0, val_loss = 0.07591935992240906, val_acc = 0.9826666712760925\n",
      "Epoch 134: Loss = 0.047384973615407944, accuracy = 0.9800000190734863, val_loss = 0.07996480166912079, val_acc = 0.9825833439826965\n",
      "Epoch 135: Loss = 0.08497259020805359, accuracy = 0.9700000286102295, val_loss = 0.0774536058306694, val_acc = 0.984083354473114\n",
      "Epoch 136: Loss = 0.06345690041780472, accuracy = 0.9800000190734863, val_loss = 0.09180718660354614, val_acc = 0.9829166531562805\n",
      "Epoch 137: Loss = 0.056554242968559265, accuracy = 0.9800000190734863, val_loss = 0.08010812103748322, val_acc = 0.9835000038146973\n",
      "Epoch 138: Loss = 0.04530855640769005, accuracy = 0.9900000095367432, val_loss = 0.07540785521268845, val_acc = 0.9837499856948853\n",
      "Epoch 139: Loss = 0.05519116297364235, accuracy = 0.9900000095367432, val_loss = 0.08743394911289215, val_acc = 0.9821666479110718\n",
      "Epoch 140: Loss = 0.05308880656957626, accuracy = 0.9800000190734863, val_loss = 0.08859999477863312, val_acc = 0.981333315372467\n",
      "Epoch 141: Loss = 0.02043796144425869, accuracy = 0.9900000095367432, val_loss = 0.08230362087488174, val_acc = 0.9832500219345093\n",
      "Epoch 142: Loss = 0.011245801113545895, accuracy = 0.9900000095367432, val_loss = 0.0943150445818901, val_acc = 0.9818333387374878\n",
      "Epoch 143: Loss = 0.030912885442376137, accuracy = 0.9900000095367432, val_loss = 0.08745652437210083, val_acc = 0.9822499752044678\n",
      "Epoch 144: Loss = 0.004553359933197498, accuracy = 1.0, val_loss = 0.07727579772472382, val_acc = 0.9825833439826965\n",
      "Epoch 145: Loss = 0.008457065559923649, accuracy = 1.0, val_loss = 0.08739931881427765, val_acc = 0.9825000166893005\n",
      "Epoch 146: Loss = 0.01625397428870201, accuracy = 0.9900000095367432, val_loss = 0.0804610624909401, val_acc = 0.9828333258628845\n",
      "Epoch 147: Loss = 0.011389139108359814, accuracy = 0.9900000095367432, val_loss = 0.08157377690076828, val_acc = 0.9825000166893005\n",
      "Epoch 148: Loss = 0.007456476800143719, accuracy = 1.0, val_loss = 0.07480684667825699, val_acc = 0.9825833439826965\n",
      "Epoch 149: Loss = 0.025740452110767365, accuracy = 0.9900000095367432, val_loss = 0.08542747050523758, val_acc = 0.9825000166893005\n",
      "Epoch 150: Loss = 0.01885983906686306, accuracy = 0.9900000095367432, val_loss = 0.0849677249789238, val_acc = 0.984083354473114\n",
      "Epoch 151: Loss = 0.08712449669837952, accuracy = 0.9900000095367432, val_loss = 0.08191780000925064, val_acc = 0.9829999804496765\n",
      "Epoch 152: Loss = 0.0232667438685894, accuracy = 0.9900000095367432, val_loss = 0.08769886195659637, val_acc = 0.981166660785675\n",
      "Epoch 153: Loss = 0.007073414511978626, accuracy = 1.0, val_loss = 0.07216499745845795, val_acc = 0.98416668176651\n",
      "Epoch 154: Loss = 0.0029654991813004017, accuracy = 1.0, val_loss = 0.08322606235742569, val_acc = 0.9819999933242798\n",
      "Epoch 155: Loss = 0.10172226279973984, accuracy = 0.9800000190734863, val_loss = 0.08811293542385101, val_acc = 0.9815833568572998\n",
      "Epoch 156: Loss = 0.02185492031276226, accuracy = 0.9900000095367432, val_loss = 0.08261901885271072, val_acc = 0.9837499856948853\n",
      "Epoch 157: Loss = 0.0104011045768857, accuracy = 0.9900000095367432, val_loss = 0.08470869809389114, val_acc = 0.9825000166893005\n",
      "Epoch 158: Loss = 0.04229489341378212, accuracy = 0.9800000190734863, val_loss = 0.08355503529310226, val_acc = 0.9826666712760925\n",
      "Epoch 159: Loss = 0.039711400866508484, accuracy = 0.9900000095367432, val_loss = 0.07990893721580505, val_acc = 0.984416663646698\n",
      "Epoch 160: Loss = 0.051351577043533325, accuracy = 0.9800000190734863, val_loss = 0.08595310151576996, val_acc = 0.984083354473114\n",
      "Epoch 161: Loss = 0.05566127225756645, accuracy = 0.9900000095367432, val_loss = 0.08825480192899704, val_acc = 0.9821666479110718\n",
      "Epoch 162: Loss = 0.045235179364681244, accuracy = 0.9900000095367432, val_loss = 0.06957808136940002, val_acc = 0.984333336353302\n",
      "Epoch 163: Loss = 0.003999889828264713, accuracy = 1.0, val_loss = 0.08547906577587128, val_acc = 0.9827499985694885\n",
      "Epoch 164: Loss = 0.004474871326237917, accuracy = 1.0, val_loss = 0.07521557062864304, val_acc = 0.9834166765213013\n",
      "Epoch 165: Loss = 0.006002506706863642, accuracy = 1.0, val_loss = 0.08330667018890381, val_acc = 0.9829999804496765\n",
      "Epoch 166: Loss = 0.014129909686744213, accuracy = 0.9900000095367432, val_loss = 0.07700324803590775, val_acc = 0.984333336353302\n",
      "Epoch 167: Loss = 0.050077978521585464, accuracy = 0.9800000190734863, val_loss = 0.07091531157493591, val_acc = 0.9849166870117188\n",
      "Epoch 168: Loss = 0.04528683051466942, accuracy = 0.9800000190734863, val_loss = 0.08068899065256119, val_acc = 0.9835833311080933\n",
      "Epoch 169: Loss = 0.002011447213590145, accuracy = 1.0, val_loss = 0.07588844001293182, val_acc = 0.9838333129882812\n",
      "Epoch 170: Loss = 0.007741517852991819, accuracy = 1.0, val_loss = 0.08206154406070709, val_acc = 0.9831666946411133\n",
      "Epoch 171: Loss = 0.021932655945420265, accuracy = 0.9900000095367432, val_loss = 0.08413700759410858, val_acc = 0.9828333258628845\n",
      "Epoch 172: Loss = 0.060224808752536774, accuracy = 0.9900000095367432, val_loss = 0.09204120188951492, val_acc = 0.9816666841506958\n",
      "Epoch 173: Loss = 0.014111890457570553, accuracy = 1.0, val_loss = 0.07595803588628769, val_acc = 0.9837499856948853\n",
      "Epoch 174: Loss = 0.04881272464990616, accuracy = 0.9900000095367432, val_loss = 0.07938618212938309, val_acc = 0.9848333597183228\n",
      "Epoch 175: Loss = 0.01131155714392662, accuracy = 1.0, val_loss = 0.07528842985630035, val_acc = 0.9850000143051147\n",
      "Epoch 176: Loss = 0.00475318031385541, accuracy = 1.0, val_loss = 0.07610243558883667, val_acc = 0.9833333492279053\n",
      "Epoch 177: Loss = 0.02746516279876232, accuracy = 0.9900000095367432, val_loss = 0.07192914187908173, val_acc = 0.9854999780654907\n",
      "Epoch 178: Loss = 0.005053872242569923, accuracy = 1.0, val_loss = 0.08092690259218216, val_acc = 0.9829166531562805\n",
      "Epoch 179: Loss = 0.025934042409062386, accuracy = 0.9900000095367432, val_loss = 0.08576514571905136, val_acc = 0.9836666584014893\n",
      "Epoch 180: Loss = 0.0032978036906570196, accuracy = 1.0, val_loss = 0.09389488399028778, val_acc = 0.9817500114440918\n",
      "Epoch 181: Loss = 0.016120141372084618, accuracy = 0.9900000095367432, val_loss = 0.08746437728404999, val_acc = 0.984083354473114\n",
      "Epoch 182: Loss = 0.017372172325849533, accuracy = 0.9800000190734863, val_loss = 0.08113530278205872, val_acc = 0.9839166402816772\n",
      "Epoch 183: Loss = 0.05488240718841553, accuracy = 0.9800000190734863, val_loss = 0.0901966542005539, val_acc = 0.9831666946411133\n",
      "Epoch 184: Loss = 0.020829396322369576, accuracy = 0.9800000190734863, val_loss = 0.07806291431188583, val_acc = 0.9837499856948853\n",
      "Epoch 185: Loss = 0.008201135322451591, accuracy = 0.9900000095367432, val_loss = 0.08365478366613388, val_acc = 0.9834166765213013\n",
      "Epoch 186: Loss = 0.006908447947353125, accuracy = 1.0, val_loss = 0.06747540831565857, val_acc = 0.9848333597183228\n",
      "Epoch 187: Loss = 0.0032785218209028244, accuracy = 1.0, val_loss = 0.07541317492723465, val_acc = 0.984666645526886\n",
      "Epoch 188: Loss = 0.00017610928625799716, accuracy = 1.0, val_loss = 0.08453262597322464, val_acc = 0.9835000038146973\n",
      "Epoch 189: Loss = 0.0025462692137807608, accuracy = 1.0, val_loss = 0.08302892744541168, val_acc = 0.984333336353302\n",
      "Epoch 190: Loss = 0.013741509057581425, accuracy = 1.0, val_loss = 0.08462158590555191, val_acc = 0.9836666584014893\n",
      "Epoch 191: Loss = 0.003201273735612631, accuracy = 1.0, val_loss = 0.08937695622444153, val_acc = 0.9839166402816772\n",
      "Epoch 192: Loss = 0.008311700075864792, accuracy = 1.0, val_loss = 0.07737495750188828, val_acc = 0.984000027179718\n",
      "Epoch 193: Loss = 0.007538744248449802, accuracy = 1.0, val_loss = 0.0837816596031189, val_acc = 0.9835833311080933\n",
      "Epoch 194: Loss = 0.015330128371715546, accuracy = 0.9900000095367432, val_loss = 0.07638008147478104, val_acc = 0.9850833415985107\n",
      "Epoch 195: Loss = 0.009127498604357243, accuracy = 1.0, val_loss = 0.07454239577054977, val_acc = 0.984749972820282\n",
      "Epoch 196: Loss = 0.05666985362768173, accuracy = 0.9800000190734863, val_loss = 0.07938554883003235, val_acc = 0.9852499961853027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197: Loss = 0.009918684139847755, accuracy = 0.9900000095367432, val_loss = 0.07453470677137375, val_acc = 0.984333336353302\n",
      "Epoch 198: Loss = 0.07167097181081772, accuracy = 0.9700000286102295, val_loss = 0.08457469195127487, val_acc = 0.9838333129882812\n",
      "Epoch 199: Loss = 0.010788810439407825, accuracy = 1.0, val_loss = 0.07588078081607819, val_acc = 0.9850000143051147\n",
      "Epoch 200: Loss = 0.0061288257129490376, accuracy = 1.0, val_loss = 0.07796331495046616, val_acc = 0.9827499985694885\n",
      "Epoch 201: Loss = 0.0317293182015419, accuracy = 0.9900000095367432, val_loss = 0.08194148540496826, val_acc = 0.9839166402816772\n",
      "Epoch 202: Loss = 0.05767468363046646, accuracy = 0.9900000095367432, val_loss = 0.0667496919631958, val_acc = 0.9860000014305115\n",
      "Epoch 203: Loss = 0.006758010946214199, accuracy = 1.0, val_loss = 0.08395413309335709, val_acc = 0.9818333387374878\n",
      "Epoch 204: Loss = 0.017120828852057457, accuracy = 0.9900000095367432, val_loss = 0.08255043625831604, val_acc = 0.9834166765213013\n",
      "Epoch 205: Loss = 0.008105610497295856, accuracy = 1.0, val_loss = 0.07738514244556427, val_acc = 0.984000027179718\n",
      "Epoch 206: Loss = 0.012682530097663403, accuracy = 0.9900000095367432, val_loss = 0.07799915224313736, val_acc = 0.984333336353302\n",
      "Epoch 207: Loss = 0.0009248029673472047, accuracy = 1.0, val_loss = 0.08411606401205063, val_acc = 0.9838333129882812\n",
      "Epoch 208: Loss = 0.006000182591378689, accuracy = 1.0, val_loss = 0.08310213685035706, val_acc = 0.98416668176651\n",
      "Epoch 209: Loss = 0.023746762424707413, accuracy = 0.9900000095367432, val_loss = 0.08300068974494934, val_acc = 0.9848333597183228\n",
      "Epoch 210: Loss = 0.003967261407524347, accuracy = 1.0, val_loss = 0.08222590386867523, val_acc = 0.984333336353302\n",
      "Epoch 211: Loss = 0.012148095294833183, accuracy = 0.9900000095367432, val_loss = 0.08692236244678497, val_acc = 0.9828333258628845\n",
      "Epoch 212: Loss = 0.002055695978924632, accuracy = 1.0, val_loss = 0.08362596482038498, val_acc = 0.9839166402816772\n",
      "Epoch 213: Loss = 0.025430403649806976, accuracy = 0.9900000095367432, val_loss = 0.07478129118680954, val_acc = 0.9855833053588867\n",
      "Epoch 214: Loss = 0.01834528148174286, accuracy = 0.9900000095367432, val_loss = 0.07649444788694382, val_acc = 0.984749972820282\n",
      "Epoch 215: Loss = 0.006047667469829321, accuracy = 1.0, val_loss = 0.08750956505537033, val_acc = 0.984333336353302\n",
      "Epoch 216: Loss = 0.02432927116751671, accuracy = 0.9900000095367432, val_loss = 0.0941270962357521, val_acc = 0.984250009059906\n",
      "Epoch 217: Loss = 0.0020726362708956003, accuracy = 1.0, val_loss = 0.0824829563498497, val_acc = 0.9839166402816772\n",
      "Epoch 218: Loss = 0.0006418999400921166, accuracy = 1.0, val_loss = 0.08035152405500412, val_acc = 0.9839166402816772\n",
      "Epoch 219: Loss = 0.038209930062294006, accuracy = 0.9700000286102295, val_loss = 0.08989804983139038, val_acc = 0.9828333258628845\n",
      "Epoch 220: Loss = 0.02809620089828968, accuracy = 0.9900000095367432, val_loss = 0.0728902742266655, val_acc = 0.9851666688919067\n",
      "Epoch 221: Loss = 0.07595577836036682, accuracy = 0.9700000286102295, val_loss = 0.07994841039180756, val_acc = 0.984250009059906\n",
      "Epoch 222: Loss = 0.03910477086901665, accuracy = 0.9900000095367432, val_loss = 0.08669860661029816, val_acc = 0.984416663646698\n",
      "Epoch 223: Loss = 0.04668847471475601, accuracy = 0.9900000095367432, val_loss = 0.09187113493680954, val_acc = 0.9836666584014893\n",
      "Epoch 224: Loss = 0.011774219572544098, accuracy = 0.9900000095367432, val_loss = 0.09075748920440674, val_acc = 0.984083354473114\n",
      "Epoch 225: Loss = 0.001981722889468074, accuracy = 1.0, val_loss = 0.1041036918759346, val_acc = 0.9821666479110718\n",
      "Epoch 226: Loss = 0.011171294376254082, accuracy = 0.9900000095367432, val_loss = 0.08786505460739136, val_acc = 0.9832500219345093\n",
      "Epoch 227: Loss = 0.04910944774746895, accuracy = 0.9800000190734863, val_loss = 0.09035340696573257, val_acc = 0.984000027179718\n",
      "Epoch 228: Loss = 0.014978375285863876, accuracy = 0.9900000095367432, val_loss = 0.0940047949552536, val_acc = 0.9832500219345093\n",
      "Epoch 229: Loss = 0.0016286156605929136, accuracy = 1.0, val_loss = 0.07644018530845642, val_acc = 0.9856666922569275\n",
      "Epoch 230: Loss = 0.10600927472114563, accuracy = 0.9900000095367432, val_loss = 0.08047065883874893, val_acc = 0.98458331823349\n",
      "Epoch 231: Loss = 0.003894997760653496, accuracy = 1.0, val_loss = 0.08176903426647186, val_acc = 0.98458331823349\n",
      "Epoch 232: Loss = 0.010664738714694977, accuracy = 0.9900000095367432, val_loss = 0.0823439210653305, val_acc = 0.984499990940094\n",
      "Epoch 233: Loss = 0.010719304904341698, accuracy = 1.0, val_loss = 0.09084322303533554, val_acc = 0.984499990940094\n",
      "Epoch 234: Loss = 0.0016491105780005455, accuracy = 1.0, val_loss = 0.08392653614282608, val_acc = 0.9854999780654907\n",
      "Epoch 235: Loss = 0.010930607095360756, accuracy = 1.0, val_loss = 0.08138568699359894, val_acc = 0.984250009059906\n",
      "Epoch 236: Loss = 0.00789431668817997, accuracy = 1.0, val_loss = 0.07478209584951401, val_acc = 0.9833333492279053\n",
      "Epoch 237: Loss = 0.02075529657304287, accuracy = 0.9900000095367432, val_loss = 0.08474014699459076, val_acc = 0.9836666584014893\n",
      "Epoch 238: Loss = 0.019220149144530296, accuracy = 0.9900000095367432, val_loss = 0.0744422897696495, val_acc = 0.9860000014305115\n",
      "Epoch 239: Loss = 0.001578162657096982, accuracy = 1.0, val_loss = 0.08027852326631546, val_acc = 0.9863333106040955\n",
      "Epoch 240: Loss = 0.02208872139453888, accuracy = 0.9900000095367432, val_loss = 0.08428912609815598, val_acc = 0.9848333597183228\n",
      "Epoch 241: Loss = 0.043439075350761414, accuracy = 0.9900000095367432, val_loss = 0.08487394452095032, val_acc = 0.9850833415985107\n",
      "Epoch 242: Loss = 0.00891315657645464, accuracy = 1.0, val_loss = 0.09484857320785522, val_acc = 0.9835000038146973\n",
      "Epoch 243: Loss = 0.020672684535384178, accuracy = 1.0, val_loss = 0.07918618619441986, val_acc = 0.9864166378974915\n",
      "Epoch 244: Loss = 0.01954536885023117, accuracy = 0.9900000095367432, val_loss = 0.08111957460641861, val_acc = 0.984250009059906\n",
      "Epoch 245: Loss = 0.011570742353796959, accuracy = 0.9900000095367432, val_loss = 0.09274250268936157, val_acc = 0.9829166531562805\n",
      "Epoch 246: Loss = 0.0021129860542714596, accuracy = 1.0, val_loss = 0.08407311141490936, val_acc = 0.9835833311080933\n",
      "Epoch 247: Loss = 0.02230948954820633, accuracy = 0.9900000095367432, val_loss = 0.08089426904916763, val_acc = 0.984499990940094\n",
      "Epoch 248: Loss = 0.006759443785995245, accuracy = 1.0, val_loss = 0.08949366211891174, val_acc = 0.984250009059906\n",
      "Epoch 249: Loss = 0.007640339899808168, accuracy = 1.0, val_loss = 0.0846397802233696, val_acc = 0.984499990940094\n",
      "Epoch 250: Loss = 0.03916613757610321, accuracy = 0.9900000095367432, val_loss = 0.07538571208715439, val_acc = 0.9871666431427002\n",
      "Epoch 251: Loss = 0.008647654205560684, accuracy = 1.0, val_loss = 0.08112604171037674, val_acc = 0.9850833415985107\n",
      "Epoch 252: Loss = 0.0006935304263606668, accuracy = 1.0, val_loss = 0.08839408308267593, val_acc = 0.984666645526886\n",
      "Epoch 253: Loss = 0.0044850073754787445, accuracy = 1.0, val_loss = 0.08749613165855408, val_acc = 0.9854166507720947\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "    \n",
    "\n",
    "      train = Variable(images.view(100,1,28,28)).to(device)\n",
    "      labels = Variable(labels).to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(train)\n",
    "\n",
    "      loss = loss_fn(outputs, labels.type(torch.LongTensor))\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "    \n",
    "      count += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        X_test = X_test.view(12000,1,28,28)\n",
    "        val_output = model(X_test)\n",
    "        val_loss = loss_fn(val_output, Y_test.type(torch.LongTensor))\n",
    "        val_accuracy = accuracy(val_output, Y_test)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss}, accuracy = {accuracy(outputs, labels)}, val_loss = {val_loss}, val_acc = {val_accuracy}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "test_set = df.values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.astype(np.float32)\n",
    "x = torch.from_numpy(test_set).view(-1,1,28,28)\n",
    "predictions = model(x)\n",
    "probs = F.softmax(predictions, dim=1)\n",
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "submission = pd.DataFrame({\"ImageId\": list(range(1, len(preds)+1)),\n",
    "                          \"Label\": preds})\n",
    "submission.to_csv(\"predictions.csv\", index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_Assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
